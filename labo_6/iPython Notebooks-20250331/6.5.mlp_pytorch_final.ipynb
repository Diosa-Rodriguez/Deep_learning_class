{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expressed-suffering",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) based on Pytorch (final)\n",
    "\n",
    "Multi-class classification problem - using a MLP with configurable number of hidden neurons - with a configurable number of classes (up to 10). It selects them from the (Fashion-)MNIST dataset, splits it up into a train and test part, does normalisation and then trains a classifier using softmax.\n",
    "\n",
    "Both datasets consist of images with 28x28 = 784 pixel each. The features refer to these pixel values of the images.\n",
    "\n",
    "You can choose MNIST or Fashion-MNIST data in cell [2]\n",
    "\n",
    "We stip down the code to show only the most relevant points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cef61d-624d-4b93-aed0-53f482b0033b",
   "metadata": {},
   "source": [
    "### Preparation for DataLoader below \n",
    "We will use a torch DataLoader below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ac812-b47b-40ab-9450-bf0091dcb396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import shortcut (just for here)\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "my_transform = v2.Compose([\n",
    "    v2.ToImage(),  # Convert to tensor, data are PIL images\n",
    "    v2.ToDtype(torch.float32, scale=False),  # convert to float; optionally normalize data \n",
    "                                            # (if True choose mean=[0.5], std=[0.5] below (why?)\n",
    "    v2.Normalize(mean=[128.], std=[128.]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e62947-b5be-4d75-885e-5c1bbeac1695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only at first execution data is downloaded, because it is saved in subfolder ../week1/data; \n",
    "#note the relative path to the 01.learning-optimization to avoid multiple downloads\n",
    "data_set = 'FashionMNIST'\n",
    "    \n",
    "if data_set == 'MNIST':\n",
    "    training_data = torchvision.datasets.MNIST(\n",
    "        root=\"../week1/data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=my_transform\n",
    "    )\n",
    "\n",
    "    test_data = torchvision.datasets.MNIST(\n",
    "        root=\"../week1/data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=my_transform\n",
    "    )    \n",
    "\n",
    "    #labels for MNIST (just for compatibility reasons)\n",
    "    labels_map = {\n",
    "        0: \"Zero\",\n",
    "        1: \"One\",\n",
    "        2: \"Two\",\n",
    "        3: \"Three\",\n",
    "        4: \"Four\",\n",
    "        5: \"Five\",\n",
    "        6: \"Six\",\n",
    "        7: \"Seven\",\n",
    "        8: \"Eight\",\n",
    "        9: \"Nine\",\n",
    "    }\n",
    "else:\n",
    "    training_data = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../week1/data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=my_transform\n",
    "    )\n",
    "\n",
    "    test_data = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../week1/data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=my_transform\n",
    "    )\n",
    "\n",
    "    #labels for FashionMNIST\n",
    "    labels_map = {\n",
    "        0: \"T-Shirt\",\n",
    "        1: \"Trouser\",\n",
    "        2: \"Pullover\",\n",
    "        3: \"Dress\",\n",
    "        4: \"Coat\",\n",
    "        5: \"Sandal\",\n",
    "        6: \"Shirt\",\n",
    "        7: \"Sneaker\",\n",
    "        8: \"Bag\",\n",
    "        9: \"Ankle Boot\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bcd5fb-d25e-4fe5-906e-386c955898a1",
   "metadata": {},
   "source": [
    "### Class NeuralNetwork\n",
    "\n",
    "This class constructs a Multilayer Perceptron with a configurable number of hidden layers. Cost function is CE. The method $propagate()$ returns the prediction $$ \\hat{y}^{(i)}=h_\\theta(\\mathbf{x}^{(i)}) $$ on the input data (can be a n x 784 matrix of n images) and $back\\_propagate()$ determines the gradients of the cost function with respect to the parameters (weights and bias for all layers) $$ \\nabla_{\\mathbf{\\theta}} J(\\mathbf{\\theta}) $$\n",
    "The method $gradient\\_descend()$ finally does the correction of the parameters with a step in the negative gradient direction, weighted with the learning rate $$\\alpha$$ for all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c173bc6-1969-4bd7-87fe-b6807f8529d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    MLP class handling the layers and doing all propagation and back propagation steps\n",
    "    all hidden layers are dense (with ReLU activation) and the last layer is softmax\n",
    "    \"\"\"\n",
    "    def __init__(self, list_num_neurons):\n",
    "        \"\"\"\n",
    "        constructor\n",
    "\n",
    "        Arguments:\n",
    "        list_num_neurons -- list of layer sizes including in- and output layer\n",
    "        \n",
    "        \"\"\"\n",
    "        self.model = torch.nn.Sequential()\n",
    "        #now we require a flatten tensor\n",
    "        self.model.add_module('flatten', torch.nn.Flatten(start_dim=1, end_dim=-1))\n",
    "        #first construct dense layers\n",
    "        for i0 in range(len(list_num_neurons)-2):\n",
    "            self.model.add_module('dense' + str(i0), torch.nn.Linear(list_num_neurons[i0], list_num_neurons[i0+1]))\n",
    "            self.model.add_module('act' + str(i0), torch.nn.ReLU())\n",
    "            \n",
    "        #finally add softmax layer\n",
    "        self.model.add_module('dense' + str(i0+1), torch.nn.Linear(list_num_neurons[-2], list_num_neurons[-1])) \n",
    "                           \n",
    "        self.cost_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "        \n",
    "                            \n",
    "    def calc_error(self, y_pred, y):\n",
    "        \"\"\"\n",
    "        get error information\n",
    "        \"\"\"\n",
    "        m = y.shape[0]\n",
    "\n",
    "        y_pred_argmax = torch.argmax(y_pred, dim=1)\n",
    "        error = torch.sum(y != y_pred_argmax) / m\n",
    "\n",
    "        return error\n",
    "\n",
    "\n",
    "    def save_images(self, training_data):\n",
    "        #we save the training and test images for quick access during evaluation\n",
    "        train_loader = torch.utils.data.DataLoader(training_data, batch_size=len(training_data.data), shuffle=False)\n",
    "        train_iterator = iter(train_loader)\n",
    "        self.train_images, self.train_labels = next(train_iterator)\n",
    "\n",
    "    \n",
    "    def get_result(self):\n",
    "        \"\"\"\n",
    "        append cost and error data to output array\n",
    "        \"\"\"     \n",
    "        # determine cost and error functions for train and validation data\n",
    "        y_pred_train = self.model(self.train_images)\n",
    "\n",
    "        return (self.cost_fn(y_pred_train, self.train_labels), \n",
    "                self.calc_error(y_pred_train, self.train_labels))\n",
    "\n",
    "        \n",
    "    def optimise(self, training_data, epochs, alpha, batch_size=16):\n",
    "        \"\"\"\n",
    "        performs epochs number of gradient descend steps and appends result to output array\n",
    "\n",
    "        Arguments:\n",
    "        training_data -- Dataset class with training data\n",
    "        epochs -- number of epochs\n",
    "        alpha -- learning rate\n",
    "        batch_size -- size of batches (1 = SGD, 1 < .. < n = mini-batch)\n",
    "        \"\"\"\n",
    "\n",
    "        #save images\n",
    "        self.save_images(training_data)\n",
    "        \n",
    "        #we define the optimiser\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=alpha, momentum=0.)\n",
    "        #self.optimizer = torch.optim.Adam(self.model.parameters(), lr=alpha)\n",
    "\n",
    "        # dataloader for training image\n",
    "        train_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        for i0 in range(0, epochs):    \n",
    "            #measure time for one epoch\n",
    "            start=time.time()\n",
    "            #set model to training mode\n",
    "            self.model.train()\n",
    "            #setup loop over all batchs\n",
    "            data_iterator = iter(train_loader)\n",
    "            for batch_iter in data_iterator:\n",
    "                #do prediction\n",
    "                y_pred = self.model(batch_iter[0])\n",
    "                #determine the loss \n",
    "                cost = self.cost_fn(y_pred, batch_iter[1])\n",
    "                #determine the error\n",
    "                self.optimizer.zero_grad()   \n",
    "                cost.backward()\n",
    "                #do the correction step\n",
    "                self.optimizer.step()\n",
    "\n",
    "            #save result\n",
    "            self.model.eval()\n",
    "            res_data = self.get_result()\n",
    "\n",
    "            #end of time measurement\n",
    "            end=time.time()\n",
    "            \n",
    "            print('result after %d epochs (dt=%1.2f s), train: cost %.5f, error %.5f' \n",
    "                         % (i0, end-start, res_data[0], res_data[1]))\n",
    "\n",
    "                         \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcfae34-9c4a-461f-b06f-d9abc093b775",
   "metadata": {},
   "source": [
    "### Sample execution of Neural Network\n",
    "\n",
    "The cell below shows how to use the class NeuralNetwork and how to perform the optimisation. To keep thing simple we do not use a validation set (torchvision dataset has only training and test set). The **time overhead** with respect to our previous versions is due to the DataLoader overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6bc169-8a62-4fc8-aab0-d88ab4b774d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the hyperparameters you want to use for the initialisation\n",
    "size_in = training_data[0][0].flatten().shape[0] #access to first image in torch.Subset train_data \n",
    "size_out = 10\n",
    "list_num_neurons = [size_in, 100, size_out]; \n",
    "NNet = NeuralNetwork(list_num_neurons)\n",
    "\n",
    "#choose the hyperparameters you want to use for training\n",
    "epochs = 5\n",
    "batchsize = 16\n",
    "learning_rate = 0.05\n",
    "NNet.optimise(training_data, epochs, learning_rate, batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b1a35f-18f4-4783-b8fd-40ac0045f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate on test image\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=len(test_data.data), shuffle=False)\n",
    "test_iterator = iter(test_loader)\n",
    "test_images, test_labels = next(test_iterator)\n",
    "\n",
    "y_pred = torch.argmax(NNet.model(test_images), axis=1)\n",
    "false_classifications = test_images[(y_pred != test_labels)]\n",
    "\n",
    "print('test error rate: %.2f %% out of %d' % (100*false_classifications.shape[0]/y_pred.shape[0], y_pred.shape[0]))\n",
    "print(false_classifications.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f452699-1cdb-46d4-be30-6179b869aca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
