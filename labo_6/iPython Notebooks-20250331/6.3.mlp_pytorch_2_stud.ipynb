{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expressed-suffering",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) based on Pytorch (2)\n",
    "\n",
    "Multi-class classification problem - using a MLP with configurable number of hidden neurons - with a configurable number of classes (up to 10). It selects them from the (Fashion-)MNIST dataset, splits it up into a train and test part, does normalisation and then trains a classifier using softmax.\n",
    "\n",
    "Both datasets consist of images with 28x28 = 784 pixel each. The features refer to these pixel values of the images.\n",
    "\n",
    "You can choose MNIST or Fashion-MNIST data in cell [2]\n",
    "\n",
    "We use the PyTorch nn-library providing all required layer types and in particular the Sequential Container to set up a MLP [torch.nn](https://pytorch.org/docs/stable/nn.html). In addition we use the DataLoader and the Datset classes for access to the data [Datasets&DataLoaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from utils import plot_img, plot_tiles, plot_error, plot_cost, plot_parameter_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79abb5de-8c68-44fd-ad11-937906cdacf9",
   "metadata": {},
   "source": [
    "### Preparation for DataLoader below \n",
    "We will use a torch DataLoader below, which can do plenty of things - in particular the data normaliation using a transform function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8d5898-d1a7-4932-904a-55049ea9e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import shortcut (just for here)\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "my_transform = v2.Compose([\n",
    "    v2.ToImage(),  # Convert to tensor, data are PIL images\n",
    "    v2.ToDtype(torch.float32, scale=False),  # convert to float; optionally normalize data \n",
    "                                            # (if True choose mean=[0.5], std=[0.5] below (why?)\n",
    "    v2.Normalize(mean=[128.], std=[128.]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9ac65-cf2d-4571-93ce-aeb172cbfbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only at first execution data is downloaded, because it is saved in subfolder ../week1/data; \n",
    "#note the relative path to the 01.learning-optimization to avoid multiple downloads\n",
    "data_set = 'FashionMNIST'\n",
    "    \n",
    "if data_set == 'MNIST':\n",
    "    training_data = torchvision.datasets.MNIST(\n",
    "        root=\"../week1/data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=my_transform\n",
    "    )\n",
    "\n",
    "    test_data = torchvision.datasets.MNIST(\n",
    "        root=\"../week1/data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=my_transform\n",
    "    )    \n",
    "\n",
    "    #labels for MNIST (just for compatibility reasons)\n",
    "    labels_map = {\n",
    "        0: \"Zero\",\n",
    "        1: \"One\",\n",
    "        2: \"Two\",\n",
    "        3: \"Three\",\n",
    "        4: \"Four\",\n",
    "        5: \"Five\",\n",
    "        6: \"Six\",\n",
    "        7: \"Seven\",\n",
    "        8: \"Eight\",\n",
    "        9: \"Nine\",\n",
    "    }\n",
    "else:\n",
    "    training_data = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../week1/data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=my_transform\n",
    "    )\n",
    "\n",
    "    test_data = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../week1/data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=my_transform\n",
    "    )\n",
    "\n",
    "    #labels for FashionMNIST\n",
    "    labels_map = {\n",
    "        0: \"T-Shirt\",\n",
    "        1: \"Trouser\",\n",
    "        2: \"Pullover\",\n",
    "        3: \"Dress\",\n",
    "        4: \"Coat\",\n",
    "        5: \"Sandal\",\n",
    "        6: \"Shirt\",\n",
    "        7: \"Sneaker\",\n",
    "        8: \"Bag\",\n",
    "        9: \"Ankle Boot\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e858214-6419-4072-b225-9256dd288878",
   "metadata": {},
   "source": [
    "### Verify Dataset type\n",
    "\n",
    "We check that the training data instance is of type Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e02ca-ff9d-4118-aad5-d369318a3812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "print(isinstance(training_data, Dataset))\n",
    "print(hasattr(training_data, '__len__'))\n",
    "print(hasattr(training_data, '__getitem__'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56529480-8390-4778-b9bb-fafa72f795e3",
   "metadata": {},
   "source": [
    "### Verify transform property\n",
    "\n",
    "We check that the training data instance has the transform method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b9e04c-f823-482c-b602-5b2f7fef365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hasattr(training_data, 'transform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48d3271-7ab3-4df6-9a0c-79bb8021f261",
   "metadata": {},
   "source": [
    "### Illustration of DataLoder concept\n",
    "It is integrated into the processing below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e17def-4d31-492e-ad09-eedd51f0b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders (we use original set (training/test_data); own data has to realize the abstract class representing 'Dataset'\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=256, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bd742e-02eb-45a4-8379-adca60a324a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup iterator\n",
    "data_iterator = iter(train_loader)\n",
    "\n",
    "#fetch first batch of images (and corresponding labels)\n",
    "images, labels = next(data_iterator)\n",
    "\n",
    "#note that the images are a 4-dim tensor; first dimension is image index in batch, second is number of channels (colors)\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "#print first ten labels -> change 'shuffle=True' to 'shuffle=False' to check that order will be always the same\n",
    "print(labels[:10])\n",
    "#plot first 10 image\n",
    "plot_tiles(images, 1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9524033d-7a03-4892-b9a9-ffd2f589be07",
   "metadata": {},
   "source": [
    "### Check the application of the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56e2fb-f58d-4cb6-bf97-b61636410826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original data\n",
    "print('tpye of original data: %r' % training_data.data.dtype)\n",
    "print('min value of original data: %r' % torch.min(training_data.data).item())\n",
    "print('max value of original data: %r' % torch.max(training_data.data).item())\n",
    "\n",
    "#loaded data\n",
    "print('\\ntpye of loaded data: %r' % images.dtype)\n",
    "print('min value of loaded data: %r' % torch.min(images).item())\n",
    "print('max value of loaded data: %r' % torch.max(images).item())\n",
    "#why is upper value not 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56652ab-593d-4c1b-a53e-2147a5d54f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup loop over all batchs\n",
    "data_iterator = iter(train_loader)\n",
    "\n",
    "start=time.time()\n",
    "#note shape of last batch\n",
    "print('shape of image batches:')\n",
    "for batch_iter in data_iterator:\n",
    "    print(batch_iter[0].numpy().shape)\n",
    "    \n",
    "end=time.time()\n",
    "print('time for transforming entire batch: %2.1f s' % (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7484b6-292a-465f-9077-6b32e1847042",
   "metadata": {},
   "source": [
    "### Dataloader inefficiency\n",
    "\n",
    "Here we only do trivial things within the data loader like type conversion and normalisation. To do this in each epoch is a considerable overhead as we will show below. We will create our own dataset - doing the transformation only once during the setup - and speed up the dataloader iteration considerably.\n",
    "\n",
    "### Create custom dataset\n",
    "\n",
    "The following dataset, which realises the interface of the PyTorch Dataset class, does the type conversion and normalisation only once in the constructor and then only gives back the prepared images. It uses our previous method `prepare_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ac812-b47b-40ab-9450-bf0091dcb396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \"\"\"owns dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, classes = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), min_max_normalise=1, flatten=0):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        dataset -- a tuple with the [images, labels] of the original dataset\n",
    "        classes -- list of classes to use for training (at least two classes must be given)\n",
    "        min_max_normalise -- whether to do min-max-normalisation (1) or rescaling (0)\n",
    "        flatten -- whether to flatten the 28x28 image to single row (=1); otherwise a new dimension is added at axis=1 (to be compatible with cnn)\n",
    "\n",
    "        \"\"\"\n",
    "        self.prepare_data(dataset, classes, min_max_normalise, flatten)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #add the missing map-dimension\n",
    "        return self.x_sel[idx], self.y_sel[idx]\n",
    "\n",
    "\n",
    "    def prepare_data(self, dataset, classes, min_max_normalise, flatten):\n",
    "        x = dataset[0]\n",
    "        y = dataset[1]\n",
    "    \n",
    "        if len(classes) < len(labels_map):\n",
    "            for label in classes:\n",
    "                print('labels chosen are: %r' % labels_map[label.item()])\n",
    "    \n",
    "        ind_sel = torch.isin(y, classes)\n",
    "    \n",
    "        x_sel = torch.zeros(x[ind_sel,:].shape, dtype=torch.float)\n",
    "        x_sel.copy_(x[ind_sel,:])\n",
    "        y_sel = torch.zeros(y[ind_sel].shape, dtype=y.dtype)\n",
    "        y_sel.copy_(y[ind_sel])\n",
    "    \n",
    "        #replace the labels such that they are in successive order\n",
    "        for i0 in range(0,len(classes)):\n",
    "            if i0 != classes[i0]:\n",
    "                y_sel[y_sel == classes[i0]] = i0\n",
    "    \n",
    "        #we give y back as simple vector -> simplifies handling below\n",
    "        #y_sel = np.reshape(y_sel, (-1,1))\n",
    "        \n",
    "        #do train and test split\n",
    "        self.num_samples = x_sel.shape[0]\n",
    "            \n",
    "        #perform normalisation, take care of converting data type to float!\n",
    "        xmax, xmin = torch.max(x_sel), torch.min(x_sel)\n",
    "        \n",
    "        if min_max_normalise:\n",
    "            x_sel = 2*(x_sel - xmin) / (xmax - xmin) - 1\n",
    "        else:\n",
    "            x_sel = x_sel / xmax \n",
    "    \n",
    "        if flatten:\n",
    "            m = x_sel.shape[0]\n",
    "            x_sel = x_sel.reshape([m,-1])\n",
    "        \n",
    "        self.x_sel = torch.unsqueeze(x_sel,1)\n",
    "        self.y_sel = y_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ce8d2-f23b-4070-a4c4-18b8a568a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now create a custom dataset based on the training dataset (we do the same later for the validation and testset)\n",
    "my_dataset = MyDataset([training_data.data, training_data.targets])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(my_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "#setup iterator\n",
    "data_iterator = iter(train_loader)\n",
    "\n",
    "#fetch first batch of images (and corresponding labels)\n",
    "images, labels = next(data_iterator)\n",
    "\n",
    "#note that the images are a 4-dim tensor; first dimension is image index in batch, second is number of channels (colors)\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "#print first ten labels -> change 'shuffle=True' to 'shuffle=False' to check that order will be always the same\n",
    "print(labels[:10])\n",
    "#plot first 10 image\n",
    "plot_tiles(images, 1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b3cf06-c5e1-46c0-a895-2229fc5c2bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup iterator\n",
    "data_iterator = iter(train_loader)\n",
    "\n",
    "#repeat the test to check the required time; it takes only a fraction of the previous data_loader\n",
    "start=time.time()\n",
    "#note shape of last batch\n",
    "print('shape of image batches:')\n",
    "for batch_iter in data_iterator:\n",
    "    print(batch_iter[0].numpy().shape)\n",
    "    \n",
    "end=time.time()\n",
    "print('time for transforming entire batch: %2.1f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "#append rows x cols tiles of images\n",
    "rows = 4\n",
    "cols = 11\n",
    "#figure size can be set\n",
    "fig_size = [8,8]\n",
    "\n",
    "#reset iterator (was at the end) and fetch a batch of images\n",
    "data_iterator = iter(train_loader)\n",
    "images, labels = next(data_iterator)\n",
    "\n",
    "#plot a few images\n",
    "plot_tiles(images, rows, cols, fig_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose a given class 0..9\n",
    "digit  = 0\n",
    "\n",
    "#fetch each time a new batch of images\n",
    "images, labels = next(data_iterator)\n",
    "\n",
    "select_images = images[labels==digit]\n",
    "\n",
    "plot_tiles(select_images, rows, select_images.shape[0] // rows, [6,6])\n",
    "print(labels_map[digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bcd5fb-d25e-4fe5-906e-386c955898a1",
   "metadata": {},
   "source": [
    "### Class NeuralNetwork\n",
    "\n",
    "This class constructs a Multilayer Perceptron with a configurable number of hidden layers. Cost function is CE. The method $propagate()$ returns the prediction $$ \\hat{y}^{(i)}=h_\\theta(\\mathbf{x}^{(i)}) $$ on the input data (can be a n x 784 matrix of n images) and $back\\_propagate()$ determines the gradients of the cost function with respect to the parameters (weights and bias for all layers) $$ \\nabla_{\\mathbf{\\theta}} J(\\mathbf{\\theta}) $$\n",
    "The method $gradient\\_descend()$ finally does the correction of the parameters with a step in the negative gradient direction, weighted with the learning rate $$\\alpha$$ for all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c173bc6-1969-4bd7-87fe-b6807f8529d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    MLP class handling the layers and doing all propagation and back propagation steps\n",
    "    all hidden layers are dense (with ReLU activation) and the last layer is softmax\n",
    "    \"\"\"\n",
    "    def __init__(self, list_num_neurons):\n",
    "        \"\"\"\n",
    "        constructor\n",
    "\n",
    "        Arguments:\n",
    "        list_num_neurons -- list of layer sizes including in- and output layer\n",
    "        \n",
    "        \"\"\"\n",
    "        self.model = torch.nn.Sequential()\n",
    "        #now we require a flatten tensor\n",
    "        self.model.add_module('flatten', torch.nn.Flatten(start_dim=1, end_dim=-1))\n",
    "        #first construct dense layers\n",
    "        for i0 in range(len(list_num_neurons)-2):\n",
    "            self.model.add_module('dense' + str(i0), torch.nn.Linear(list_num_neurons[i0], list_num_neurons[i0+1]))\n",
    "            self.model.add_module('act' + str(i0), torch.nn.Sigmoid())\n",
    "            \n",
    "        #finally add softmax layer\n",
    "        #we don't require activation function because it is included (for numerical reasons) in the cross \n",
    "        #entropy cost below; alternative is logSoftmax together with NLLLoss cost function\n",
    "        self.model.add_module('dense' + str(i0+1), torch.nn.Linear(list_num_neurons[-2], list_num_neurons[-1]))                    \n",
    "        \n",
    "        self.cost_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "        #self.optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        #used to save results\n",
    "        self.result_data = torch.tensor([])\n",
    "        \n",
    "        #we keep a global step counter, thus that optimise can be called \n",
    "        #several times with different settings\n",
    "        self.epoch_counter = 0 \n",
    "        \n",
    "    def propagate(self, x):\n",
    "        \"\"\"\n",
    "        calculates the function estimation based on current parameters\n",
    "        \"\"\"    \n",
    "        y_pred = self.model(x)\n",
    "\n",
    "        return y_pred\n",
    "           \n",
    "     \n",
    "    def back_propagate(self, cost):\n",
    "        \"\"\"\n",
    "        calculates the backpropagation results based on expected output y\n",
    "        this function must be performed AFTER the corresponding propagte step\n",
    "        \"\"\"    \n",
    "        #set gradient values to zero\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    " \n",
    "\n",
    "    def cost_funct(self, y_pred, y):\n",
    "        \"\"\"\n",
    "        calculates the MSE loss function\n",
    "        \"\"\"\n",
    "        cost = self.cost_fn(y_pred, y)\n",
    "        \n",
    "        return cost\n",
    "    \n",
    "         \n",
    "    def gradient_descend(self, alpha):\n",
    "        \"\"\"\n",
    "        does the gradient descend based on results from last back_prop step with learning rate alpha\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            for param in self.model.parameters():\n",
    "                param -= alpha * param.grad\n",
    "            \n",
    "         \n",
    "    def calc_error(self, y_pred, y):\n",
    "        \"\"\"\n",
    "        get error information\n",
    "        \"\"\"\n",
    "        m = y.shape[0]\n",
    "\n",
    "        y_pred_argmax = torch.argmax(y_pred, dim=1)\n",
    "        error = torch.sum(y != y_pred_argmax) / m\n",
    "\n",
    "        return error\n",
    "\n",
    "\n",
    "    def save_images(self):\n",
    "        #we save the training and test images for quick access during evaluation\n",
    "        train_loader = torch.utils.data.DataLoader(self.data['train'], batch_size=len(self.data['train']), shuffle=False)\n",
    "        train_iterator = iter(train_loader)\n",
    "        self.train_images, self.train_labels = next(train_iterator)\n",
    "\n",
    "        valid_loader = torch.utils.data.DataLoader(self.data['valid'], batch_size=len(self.data['valid']), shuffle=False)\n",
    "        valid_iterator = iter(valid_loader)\n",
    "        self.valid_images, self.valid_labels = next(valid_iterator)\n",
    "\n",
    "    \n",
    "    def append_result(self):\n",
    "        \"\"\"\n",
    "        append cost and error data to output array\n",
    "        \"\"\"     \n",
    "        # determine cost and error functions for train and validation data\n",
    "        y_pred_train = self.propagate(self.train_images)\n",
    "        y_pred_val = self.propagate(self.valid_images)\n",
    "\n",
    "        res_data = torch.tensor([[self.cost_funct(y_pred_train, self.train_labels), \n",
    "                                  self.calc_error(y_pred_train, self.train_labels),\n",
    "                                  self.cost_funct(y_pred_val, self.valid_labels), \n",
    "                                  self.calc_error(y_pred_val, self.valid_labels)]])\n",
    "        \n",
    "        self.result_data = torch.cat((self.result_data, res_data), 0)\n",
    "\n",
    "        #increase epoch counter here (used for plot routines below)\n",
    "        self.epoch_counter += 1 \n",
    "        \n",
    "        return res_data\n",
    "\n",
    "        \n",
    "    def optimise(self, data, epochs, alpha, batch_size=0, debug=0):\n",
    "        \"\"\"\n",
    "        performs epochs number of gradient descend steps and appends result to output array\n",
    "\n",
    "        Arguments:\n",
    "        data -- dictionary with NORMALISED data\n",
    "        epochs -- number of epochs\n",
    "        alpha -- learning rate\n",
    "        batch_size -- size of batches (1 = SGD, 1 < .. < n = mini-batch)\n",
    "        debug -- integer value; get info on gradient descend step every debug-step (0 -> no output)\n",
    "        \"\"\"\n",
    "        #access to data from other methods\n",
    "        self.data = data\n",
    "        #save images\n",
    "        self.save_images()\n",
    "\n",
    "        # dataloader for training image\n",
    "        if batch_size == 0:\n",
    "            batch_size = len(data['train'])\n",
    "        train_loader = torch.utils.data.DataLoader(data['train'], batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # save results before 1st step\n",
    "        if self.epoch_counter == 0:\n",
    "            res_data = self.append_result()\n",
    "\n",
    "        for i0 in range(0, epochs):    \n",
    "            #measure time for one epoch\n",
    "            start=time.time()\n",
    "            #set model to training mode\n",
    "            self.model.train()\n",
    "            #setup loop over all batchs\n",
    "            data_iterator = iter(train_loader)\n",
    "            for batch_iter in data_iterator:\n",
    "                #do prediction\n",
    "                y_pred = self.propagate(batch_iter[0])\n",
    "                #determine the loss \n",
    "                cost = self.cost_funct(y_pred, batch_iter[1])\n",
    "                #determine the error\n",
    "                self.back_propagate(cost)\n",
    "                #do the correction step\n",
    "                self.gradient_descend(alpha)\n",
    "\n",
    "            #save result\n",
    "            self.model.eval()\n",
    "            res_data = self.append_result()\n",
    "\n",
    "            #end of time measurement\n",
    "            end=time.time()\n",
    "            \n",
    "            if debug and np.mod(i0, debug) == 0:\n",
    "                print('result after %d epochs (dt=%1.2f s), train: cost %.5f, error %.5f ; validation: cost %.5f, error %.5f'\n",
    "                    % (self.epoch_counter-1, end-start, res_data[0, 0].item(), res_data[0, 1].item(), \\\n",
    "                                                                res_data[0, 2].item(), res_data[0, 3].item()))\n",
    "\n",
    "        if debug:\n",
    "            print('result after %d epochs, train: cost %.5f, error %.5f ; validation: cost %.5f, error %.5f'\n",
    "                  % (self.epoch_counter-1, res_data[0, 0].item(), res_data[0, 1].item(), \\\n",
    "                                                                res_data[0, 2].item(), res_data[0, 3].item()))\n",
    "                        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcfae34-9c4a-461f-b06f-d9abc093b775",
   "metadata": {},
   "source": [
    "### Sample execution of Neural Network\n",
    "\n",
    "The cell below shows how to use the class NeuralNetwork and how to perform the optimisation. The training and test data is given as dictionary in the call to the method $optimise()$. The classes (from 2 to 10) can be chosen via the `classes` list. This method can be called several times in a row with different arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e5245-456f-4026-8978-8a1b8776ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the categories\n",
    "classes = torch.tensor([0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "#split data in train and validation\n",
    "validation_size = 0.2\n",
    "\n",
    "#further split in train and validation data\n",
    "validation_size = 0.2\n",
    "valid_ind = int(len(training_data)*(1-validation_size))\n",
    "\n",
    "#create custom training and validation data set\n",
    "train_dataset = MyDataset([training_data.data[:valid_ind,:], training_data.targets[:valid_ind]], classes=classes)\n",
    "valid_dataset = MyDataset([training_data.data[valid_ind:,:], training_data.targets[valid_ind:]], classes=classes)\n",
    "\n",
    "\n",
    "#data is arranged as dictionary with quick access through respective keys\n",
    "data = {'train' : train_dataset, 'valid' : valid_dataset}\n",
    "\n",
    "#choose the hyperparameters you want to use for the initialisation\n",
    "size_in = train_dataset[0][0].flatten().shape[0] #access to first image in torch.Subset train_data \n",
    "size_out = 10\n",
    "list_num_neurons = [size_in, 100, size_out]; \n",
    "NNet = NeuralNetwork(list_num_neurons)\n",
    "\n",
    "#choose the hyperparameters you want to use for training\n",
    "epochs = 40\n",
    "batchsize = 16\n",
    "learning_rate = 0.05\n",
    "NNet.optimise(data, epochs, learning_rate, batchsize, debug=5)\n",
    "\n",
    "\n",
    "plot_error(NNet)\n",
    "plot_cost(NNet)\n",
    "\n",
    "plot_parameter_hist(NNet)\n",
    "\n",
    "#also prepare the test dataset\n",
    "test_dataset = MyDataset([test_data.data, test_data.targets], classes=classes)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "test_iterator = iter(test_loader)\n",
    "test_images, test_labels = next(test_iterator)\n",
    "\n",
    "y_pred = torch.argmax(NNet.propagate(test_images), axis=1)\n",
    "false_classifications = test_images[(y_pred != test_labels)]\n",
    "\n",
    "print('test error rate: %.2f %% out of %d' % (100*false_classifications.shape[0]/y_pred.shape[0], y_pred.shape[0]))\n",
    "print(false_classifications.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b7882-711e-4aea-8e93-6aedd179c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyse false classified training on test images\n",
    "#also prepare the test dataset\n",
    "test_dataset = MyDataset([test_data.data, test_data.targets], classes=classes)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "test_iterator = iter(test_loader)\n",
    "test_images, test_labels = next(test_iterator)\n",
    "\n",
    "y_pred = torch.argmax(NNet.propagate(test_images), axis=1)\n",
    "false_classifications = test_images[(y_pred != test_labels)]\n",
    "\n",
    "print('test error rate: %.2f %% out of %d' % (100*false_classifications.shape[0]/y_pred.shape[0], y_pred.shape[0]))\n",
    "print(false_classifications.shape)\n",
    "\n",
    "#append rows x cols tiles of digits\n",
    "rows = 7\n",
    "cols = 8\n",
    "#figure size can be set\n",
    "fig_size = [8,8]\n",
    "\n",
    "plot_tiles(false_classifications.reshape([-1,28,28]), rows, cols, fig_size)\n",
    "\n",
    "#print the correct labels (for FashionMNIST)\n",
    "if rows*cols < false_classifications.shape[0]:\n",
    "    false_classifications_y = test_labels[y_pred != test_labels][:rows*cols]\n",
    "else:\n",
    "    false_classifications_y = np.append(test_labels[y_pred != test_labels], np.ones(rows*cols - false_classifications.shape[0])*-1)\n",
    "print(false_classifications_y.reshape([cols,rows]).T.to(torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee00a7a-f1d3-45df-8ea9-b52abdf583c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise weights of the first layer\n",
    "\n",
    "print('we have %r weight vectors in layer [0]' % NNet.model[1].weight.shape[1])\n",
    "print('choose a suitable combination of rows and cols below to plot them')\n",
    "\n",
    "rows = 5\n",
    "cols = 20\n",
    "#figure size can be set\n",
    "fig_size = [14,6]\n",
    "\n",
    "plot_tiles(NNet.model[1].weight.detach().reshape([-1,28,28]), rows, cols, fig_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c3bc17-59c2-4b06-abbb-88251ed5a40e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
